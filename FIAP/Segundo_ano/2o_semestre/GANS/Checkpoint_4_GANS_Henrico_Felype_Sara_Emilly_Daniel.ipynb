{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 4 - Advanced Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aluno\n",
    "> Henrico Nardelli Bela | \n",
    "> Emilly Gabrielly | \n",
    "> Felype Nunes | \n",
    "> Sara Leal | \n",
    "> Daniel Faria | \n",
    "## RM\n",
    "> RM 95985 | \n",
    "> RM 94437 | \n",
    "> RM 96232 | \n",
    "> RM 96302 | \n",
    "> RM 94026 | \n",
    "## Turma\n",
    "> 2TIAR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olá pessoal, tudo bem?\n",
    "\n",
    "\n",
    "\n",
    "Para o quarto entregáveis da nossa disciplina de “Generative Adversarial Networks & Advanced Nets” peço que seja entregue uma codificação exemplo contendo projeto no tema “Classificação de Texto com Transformers”.\n",
    "\n",
    "\n",
    "\n",
    "Esta atividade tem como objetivo trazer os conceitos introduzidos em nossas últimas aulas, de modo a iniciá-los no uso prático de modelos Transformers da Hugging Face para tarefas em classificação de texto.\n",
    "\n",
    "\n",
    "\n",
    "Passos da atividade:\n",
    "\n",
    "\n",
    "\n",
    "Escolha de uma Tarefa: Escolham uma tarefa de classificação de texto simples, sugiro problemas como análise de sentimento ou classificação multi classe de notícias. Por exemplo: classificar sentimentos em tweets em \"positivos\" ou \"negativos”;\n",
    "\n",
    "\n",
    "\n",
    "Obtenção de Dados: Procurem e coletem um conjunto de dados relacionado à tarefa escolhida;\n",
    "\n",
    "\n",
    "\n",
    "Pré-processamento de Dados: A codificação exemplo deve conter algum modo de pré-processar os dados, incluindo tokenização e codificação de rótulos, se necessário;\n",
    "\n",
    "\n",
    "\n",
    "Seleção de um Modelo: Podem escolher um modelo Transformers pré-treinado da Hugging Face, como BERT ou DistilBERT, que seja adequado para a tarefa de classificação escolhida;\n",
    "\n",
    "\n",
    "\n",
    "Relatório: Ao final da experimentação, vocês devem devem preparar um breve relatório que descreva o problema, os dados, o modelo escolhido, o código implementado e os resultados obtidos. Pode estar junto a codificação em formato de notebook Python.\n",
    "\n",
    "\n",
    "\n",
    "Ref. https://huggingface.co/blog/sentiment-analysis-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) negative 0.9435\n",
      "2) neutral 0.0486\n",
      "3) positive 0.0079\n"
     ]
    }
   ],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Definindo uma função de pré-processamento de texto\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    # Iterando por cada palavra no texto\n",
    "    for t in text.split(\" \"):\n",
    "        # Substituindo nomes de usuário por '@user' se começarem com '@' e tiverem mais de um caractere\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        # Substituindo links por 'http' se começarem com 'http'\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    # Unindo as palavras de volta em um único texto\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Definindo o modelo pré-treinado a ser utilizado\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "\n",
    "# Carregando o tokenizador associado ao modelo\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# Carregando a configuração do modelo\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "# Carregando o modelo pré-treinado para classificação de sequências\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# Definindo o texto de exemplo\n",
    "text = \"The world war 2 was really disgusting\"\n",
    "\n",
    "# Aplicando o pré-processamento ao texto de exemplo\n",
    "text = preprocess(text)\n",
    "\n",
    "# Codificando o texto utilizando o tokenizador\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# Passando o texto codificado para o modelo e obtendo a saída\n",
    "output = model(**encoded_input)\n",
    "\n",
    "# Extraindo os escores de probabilidade da saída do modelo\n",
    "scores = output[0][0].detach().numpy()\n",
    "\n",
    "# Aplicando a função softmax para obter probabilidades normalizadas\n",
    "scores = softmax(scores)\n",
    "\n",
    "# Classificando as probabilidades em ordem decrescente\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "\n",
    "# Iterando pelas classificações de sentimentos em ordem decrescente de probabilidade\n",
    "for i in range(scores.shape[0]):\n",
    "    # Obtendo o rótulo (label) correspondente ao ranking atual\n",
    "    l = config.id2label[ranking[i]]\n",
    "    # Obtendo a probabilidade correspondente ao ranking atual\n",
    "    s = scores[ranking[i]]\n",
    "    # Imprimindo o resultado com o índice, rótulo e probabilidade arredondada\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relatório de Análise de Sentimento usando o modelo Cardiff Twitter RoBERTa\n",
    "\n",
    "## 1. Introdução\n",
    "\n",
    "O objetivo deste relatório é descrever o problema abordado, os dados utilizados, o modelo escolhido, o código implementado e os resultados obtidos na análise de sentimento de um texto. Para isso, utilizou-se o modelo Cardiff Twitter RoBERTa para realizar a classificação de sentimentos em um texto de exemplo.\n",
    "\n",
    "## 2. Problema\n",
    "\n",
    "O problema abordado neste código é a análise de sentimento em um texto. O objetivo é determinar o sentimento expresso no texto, classificando-o como positivo, negativo ou neutro. Isso é útil em várias aplicações, como monitoramento de mídias sociais, análise de opinião de clientes e detecção de tendências de mercado.\n",
    "\n",
    "## 3. Dados\n",
    "\n",
    "Não há dados externos sendo usados neste código, uma vez que estamos avaliando o desempenho do modelo pré-treinado Cardiff Twitter RoBERTa em um texto de exemplo (\"The world war 2 was really disgusting\"). Os dados utilizados neste contexto são textos de exemplo fornecidos no código. Entretanto, os dados de treinamento do modelo foi executado pelo tweetnlp, uma biblioteca criada pelo twitter, Ref: https://github.com/cardiffnlp/tweetnlp e https://huggingface.co/docs/datasets/load_hub (RottenTomatoes)\n",
    "\n",
    "### 3.1 Preprocessamento\n",
    "\n",
    "Para obter um melhor resultado, foi inserido um preprocessamento dos dados que serão enviados para a predição do modelo. Como *Tokenizador* e tambem uma função simples para verificar se há \"@\" no texto, fazendo a troca por \"@user\", afim de obter uma maior assertividade pois o modelo prétreinado está acostumando a ver dados neste tipo de forma.\n",
    "\n",
    "\n",
    "## 4. Modelo Escolhido\n",
    "\n",
    "O modelo escolhido para a análise de sentimento é o \"Cardiff Twitter RoBERTa\", que é uma variação do modelo RoBERTa pré-treinado especificamente voltado para tarefas de classificação de sentimentos em texto. Ele é treinado em dados do Twitter e é conhecido por ser eficaz na tarefa de análise de sentimentos em mídias sociais.\n",
    "\n",
    "## 5. Código Implementado\n",
    "\n",
    "O código implementado realiza as seguintes etapas:\n",
    "\n",
    "- Importa as bibliotecas necessárias, incluindo Transformers, NumPy e SciPy.\n",
    "- Define uma função de pré-processamento de texto para substituir nomes de usuário e links por marcadores, a fim de proteger a privacidade e simplificar o texto.\n",
    "- Define o modelo pré-treinado Cardiff Twitter RoBERTa e carrega o tokenizador e a configuração associados.\n",
    "- Pré-processa o texto de exemplo, substituindo nomes de usuário e links.\n",
    "- Codifica o texto usando o tokenizador.\n",
    "- Passa o texto codificado para o modelo e obtém a saída.\n",
    "- Calcula os escores de probabilidade de sentimento usando a função softmax.\n",
    "- Classifica os sentimentos em ordem decrescente de probabilidade e imprime os resultados.\n",
    "\n",
    "## 6. Resultados Obtidos\n",
    "\n",
    "Os resultados obtidos com o código são os seguintes, com base no texto de exemplo \"Covid cases are increasing fast!\":\n",
    "\n",
    "1) NEGATIVE 0.9435\n",
    "2) NEUTRAL 0.0486\n",
    "3) POSITIVE 0.0079\n",
    "\n",
    "Os resultados indicam que o modelo classificou o texto como \"LABEL_2\" com uma probabilidade de 94%, o que provavelmente representa um sentimento negativo. Os outros sentimentos possíveis, \"LABEL_1\" (neutro) e \"LABEL_0\" (positivo), tiveram probabilidades menores de 0,04% e 0,007%, respectivamente.\n",
    "\n",
    "Isso sugere que o texto de exemplo expressa um sentimento negativo em relação á afirmação de que a segunda guerra mundial foi desagradavel. No entanto, vale ressaltar que a precisão do modelo pode variar dependendo do contexto e dos dados utilizados para o treinamento.\n",
    "\n",
    "## 7. Conclusão\n",
    "\n",
    "O código apresentado demonstra a utilização do modelo Cardiff Twitter RoBERTa para a análise de sentimento em um texto específico. O modelo fornece probabilidades de sentimentos positivos, negativos e neutros para o texto de entrada, ajudando a entender como o sentimento é expresso no texto. Esse tipo de análise pode ser valioso em várias aplicações, como monitoramento de redes sociais e análise de opinião de clientes. No entanto, a interpretação dos resultados deve levar em consideração a natureza probabilística da classificação de sentimentos e a necessidade de treinamento em dados específicos, quando aplicável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
